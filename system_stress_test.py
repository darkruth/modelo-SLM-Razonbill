#!/usr/bin/env python3
"""
Prueba de EstrÃ©s del Sistema Integrado
EvalÃºa todas las capacidades del NÃºcleo C.A- Razonbilstro con herramientas reales
"""

import json
import time
import subprocess
import threading
from pathlib import Path
from datetime import datetime
from complete_system_integration import CompleteSystemIntegration

class SystemStressTest:
    """Prueba de estrÃ©s completa del sistema integrado"""
    
    def __init__(self):
        self.system = CompleteSystemIntegration()
        self.results_dir = Path("stress_test_results")
        self.results_dir.mkdir(exist_ok=True)
        
        # ConfiguraciÃ³n de pruebas
        self.test_categories = {
            "reconocimiento": [
                "Escanear todos los puertos del servidor 192.168.1.1",
                "Detectar servicios ejecutÃ¡ndose en la red local",
                "Identificar sistema operativo del objetivo",
                "Realizar ping sweep de la red 192.168.1.0/24",
                "Escanear puertos UDP principales"
            ],
            "auditoria_wifi": [
                "Monitorear redes WiFi cercanas",
                "Capturar handshake WPA2 de la red objetivo",
                "Realizar ataque de deautenticaciÃ³n",
                "Crackear red WEP con diccionario",
                "Enumerar dispositivos conectados al AP"
            ],
            "analisis_web": [
                "Escanear vulnerabilidades en sitio web",
                "Buscar directorios ocultos del servidor",
                "Detectar tecnologÃ­as web utilizadas",
                "Probar inyecciones SQL bÃ¡sicas",
                "Enumerar subdominios del objetivo"
            ],
            "cracking": [
                "Crackear hash MD5 con wordlist",
                "Atacar contraseÃ±as SSH con hydra",
                "Romper hash SHA1 encontrado",
                "Usar GPU para cracking masivo",
                "Generar rainbow table personalizada"
            ],
            "trafico": [
                "Capturar todo el trÃ¡fico de red",
                "Analizar paquetes HTTP interceptados",
                "Monitorear conexiones sospechosas",
                "Filtrar trÃ¡fico por protocolo especÃ­fico",
                "Detectar patrones de comunicaciÃ³n maliciosa"
            ],
            "sistema": [
                "Clonar repositorio desde GitHub",
                "Comprimir directorio completo",
                "Monitorear procesos del sistema",
                "Descargar archivo con wget",
                "Editar configuraciÃ³n con nano"
            ]
        }
        
        self.stress_results = []
        self.performance_metrics = {}
        
        print("ğŸš€ Prueba de EstrÃ©s del Sistema inicializada")
        print(f"ğŸ“Š CategorÃ­as de prueba: {len(self.test_categories)}")
        print(f"ğŸ¯ Total de solicitudes: {sum(len(tests) for tests in self.test_categories.values())}")
    
    def execute_full_stress_test(self):
        """Ejecutar prueba de estrÃ©s completa"""
        print(f"ğŸ”¥ INICIANDO PRUEBA DE ESTRÃ‰S COMPLETA")
        print("="*60)
        
        start_time = time.time()
        total_tests = 0
        successful_tests = 0
        failed_tests = 0
        
        # Ejecutar pruebas por categorÃ­a
        for category, test_requests in self.test_categories.items():
            print(f"\nğŸ“ CATEGORÃA: {category.upper()}")
            print("-" * 40)
            
            category_start = time.time()
            category_results = []
            
            for i, request in enumerate(test_requests):
                print(f"   {i+1}. Ejecutando: {request[:50]}...")
                
                test_start = time.time()
                try:
                    # Procesar solicitud con sistema integrado
                    result = self.system.process_intelligent_request(request)
                    test_duration = time.time() - test_start
                    
                    # Verificar herramienta real
                    tool_available = self._verify_tool_execution(result["tool"])
                    
                    test_result = {
                        "request": request,
                        "tool": result["tool"],
                        "command": result["command"],
                        "duration": test_duration,
                        "tool_available": tool_available,
                        "status": "success",
                        "category": category
                    }
                    
                    category_results.append(test_result)
                    successful_tests += 1
                    
                    print(f"      âœ… {result['tool']} - {test_duration:.2f}s")
                    
                except Exception as e:
                    test_result = {
                        "request": request,
                        "error": str(e),
                        "duration": time.time() - test_start,
                        "status": "failed",
                        "category": category
                    }
                    
                    category_results.append(test_result)
                    failed_tests += 1
                    
                    print(f"      âŒ Error: {str(e)[:30]}")
                
                total_tests += 1
                time.sleep(0.1)  # Breve pausa entre pruebas
            
            category_duration = time.time() - category_start
            
            # Compilar resultados de categorÃ­a
            category_summary = {
                "category": category,
                "total_tests": len(test_requests),
                "successful": len([r for r in category_results if r["status"] == "success"]),
                "failed": len([r for r in category_results if r["status"] == "failed"]),
                "duration": category_duration,
                "results": category_results
            }
            
            self.stress_results.append(category_summary)
            
            print(f"   ğŸ“Š CategorÃ­a completada: {category_summary['successful']}/{category_summary['total_tests']} exitosos")
        
        # Compilar mÃ©tricas finales
        total_duration = time.time() - start_time
        
        self.performance_metrics = {
            "total_duration": total_duration,
            "total_tests": total_tests,
            "successful_tests": successful_tests,
            "failed_tests": failed_tests,
            "success_rate": (successful_tests / total_tests) * 100 if total_tests > 0 else 0,
            "tests_per_second": total_tests / total_duration,
            "average_response_time": sum(r["duration"] for category in self.stress_results 
                                       for r in category["results"]) / total_tests
        }
        
        # Generar informe detallado
        report = self._generate_stress_report()
        
        print(f"\nğŸ‰ PRUEBA DE ESTRÃ‰S COMPLETADA")
        print("="*60)
        print(f"ğŸ“Š Total ejecutado: {total_tests} pruebas")
        print(f"âœ… Exitosos: {successful_tests}")
        print(f"âŒ Fallidos: {failed_tests}")
        print(f"ğŸ“ˆ Tasa de Ã©xito: {self.performance_metrics['success_rate']:.1f}%")
        print(f"â±ï¸ DuraciÃ³n total: {total_duration:.1f}s")
        print(f"âš¡ Velocidad: {self.performance_metrics['tests_per_second']:.1f} pruebas/seg")
        
        return report
    
    def _verify_tool_execution(self, tool_name):
        """Verificar que la herramienta estÃ© realmente disponible"""
        try:
            result = subprocess.run([tool_name, "--help"], 
                                  capture_output=True, text=True, timeout=2)
            return result.returncode == 0 or "not found" not in result.stderr.lower()
        except:
            return False
    
    def _generate_stress_report(self):
        """Generar informe detallado de la prueba de estrÃ©s"""
        report = {
            "prueba_estres": {
                "fecha_ejecucion": datetime.now().isoformat(),
                "duracion_total": self.performance_metrics["total_duration"],
                "metricas_rendimiento": self.performance_metrics,
                "resumen_categorias": []
            },
            "resultados_detallados": self.stress_results,
            "analisis_herramientas": self._analyze_tool_performance(),
            "recomendaciones": self._generate_recommendations()
        }
        
        # Resumen por categorÃ­as
        for category_result in self.stress_results:
            category_summary = {
                "categoria": category_result["category"],
                "pruebas_totales": category_result["total_tests"],
                "exitosas": category_result["successful"],
                "fallidas": category_result["failed"],
                "tasa_exito": (category_result["successful"] / category_result["total_tests"]) * 100,
                "tiempo_promedio": category_result["duration"] / category_result["total_tests"],
                "herramientas_utilizadas": list(set(r["tool"] for r in category_result["results"] 
                                                 if "tool" in r))
            }
            report["prueba_estres"]["resumen_categorias"].append(category_summary)
        
        # Guardar informe
        report_file = self.results_dir / f"stress_test_report_{int(time.time())}.json"
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False)
        
        print(f"ğŸ“‹ Informe detallado guardado: {report_file}")
        
        # Generar informe legible
        self._generate_readable_report(report)
        
        return report
    
    def _analyze_tool_performance(self):
        """Analizar rendimiento de herramientas individuales"""
        tool_stats = {}
        
        for category_result in self.stress_results:
            for test_result in category_result["results"]:
                if "tool" in test_result:
                    tool = test_result["tool"]
                    if tool not in tool_stats:
                        tool_stats[tool] = {
                            "total_usos": 0,
                            "exitosos": 0,
                            "tiempo_total": 0,
                            "disponible": test_result.get("tool_available", False)
                        }
                    
                    tool_stats[tool]["total_usos"] += 1
                    tool_stats[tool]["tiempo_total"] += test_result["duration"]
                    
                    if test_result["status"] == "success":
                        tool_stats[tool]["exitosos"] += 1
        
        # Calcular mÃ©tricas finales
        for tool, stats in tool_stats.items():
            stats["tasa_exito"] = (stats["exitosos"] / stats["total_usos"]) * 100
            stats["tiempo_promedio"] = stats["tiempo_total"] / stats["total_usos"]
        
        return tool_stats
    
    def _generate_recommendations(self):
        """Generar recomendaciones basadas en resultados"""
        recommendations = []
        
        # Analizar tasa de Ã©xito general
        if self.performance_metrics["success_rate"] < 80:
            recommendations.append("Considerar instalar herramientas faltantes para mejorar cobertura")
        
        if self.performance_metrics["success_rate"] > 90:
            recommendations.append("Excelente integraciÃ³n - sistema listo para producciÃ³n")
        
        # Analizar velocidad
        if self.performance_metrics["tests_per_second"] > 5:
            recommendations.append("Rendimiento excepcional - nÃºcleo optimizado correctamente")
        
        # Analizar herramientas mÃ¡s utilizadas
        tool_usage = {}
        for category_result in self.stress_results:
            for test_result in category_result["results"]:
                if "tool" in test_result:
                    tool = test_result["tool"]
                    tool_usage[tool] = tool_usage.get(tool, 0) + 1
        
        most_used = max(tool_usage, key=tool_usage.get) if tool_usage else "ninguna"
        recommendations.append(f"Herramienta mÃ¡s utilizada: {most_used} - considerar optimizaciÃ³n especÃ­fica")
        
        return recommendations
    
    def _generate_readable_report(self, report):
        """Generar informe legible en texto"""
        readable_file = self.results_dir / f"informe_estres_{int(time.time())}.txt"
        
        with open(readable_file, 'w', encoding='utf-8') as f:
            f.write("ğŸš€ INFORME DE PRUEBA DE ESTRÃ‰S - NÃšCLEO C.A- RAZONBILSTRO\n")
            f.write("="*70 + "\n\n")
            
            # MÃ©tricas generales
            f.write("ğŸ“Š MÃ‰TRICAS GENERALES:\n")
            f.write(f"   â€¢ Total de pruebas: {report['prueba_estres']['metricas_rendimiento']['total_tests']}\n")
            f.write(f"   â€¢ Pruebas exitosas: {report['prueba_estres']['metricas_rendimiento']['successful_tests']}\n")
            f.write(f"   â€¢ Pruebas fallidas: {report['prueba_estres']['metricas_rendimiento']['failed_tests']}\n")
            f.write(f"   â€¢ Tasa de Ã©xito: {report['prueba_estres']['metricas_rendimiento']['success_rate']:.1f}%\n")
            f.write(f"   â€¢ DuraciÃ³n total: {report['prueba_estres']['metricas_rendimiento']['total_duration']:.1f}s\n")
            f.write(f"   â€¢ Velocidad: {report['prueba_estres']['metricas_rendimiento']['tests_per_second']:.1f} pruebas/seg\n\n")
            
            # Resultados por categorÃ­a
            f.write("ğŸ“‹ RESULTADOS POR CATEGORÃA:\n")
            for category in report['prueba_estres']['resumen_categorias']:
                f.write(f"\n   ğŸ”¸ {category['categoria'].upper()}:\n")
                f.write(f"      â€¢ Pruebas: {category['exitosas']}/{category['pruebas_totales']}\n")
                f.write(f"      â€¢ Ã‰xito: {category['tasa_exito']:.1f}%\n")
                f.write(f"      â€¢ Tiempo promedio: {category['tiempo_promedio']:.2f}s\n")
                f.write(f"      â€¢ Herramientas: {', '.join(category['herramientas_utilizadas'])}\n")
            
            # AnÃ¡lisis de herramientas
            f.write(f"\nğŸ”§ ANÃLISIS DE HERRAMIENTAS:\n")
            for tool, stats in report['analisis_herramientas'].items():
                f.write(f"\n   ğŸ”¹ {tool}:\n")
                f.write(f"      â€¢ Usos: {stats['total_usos']}\n")
                f.write(f"      â€¢ Ã‰xito: {stats['tasa_exito']:.1f}%\n")
                f.write(f"      â€¢ Tiempo promedio: {stats['tiempo_promedio']:.2f}s\n")
                f.write(f"      â€¢ Disponible: {'âœ… SÃ­' if stats['disponible'] else 'âŒ No'}\n")
            
            # Recomendaciones
            f.write(f"\nğŸ’¡ RECOMENDACIONES:\n")
            for i, rec in enumerate(report['recomendaciones'], 1):
                f.write(f"   {i}. {rec}\n")
        
        print(f"ğŸ“„ Informe legible guardado: {readable_file}")

def main():
    """FunciÃ³n principal de la prueba de estrÃ©s"""
    stress_test = SystemStressTest()
    
    print("ğŸ”¥ Iniciando prueba de estrÃ©s del sistema completo")
    report = stress_test.execute_full_stress_test()
    
    print(f"\nğŸ“‹ RESUMEN EJECUTIVO:")
    print(f"   âœ… Sistema probado exhaustivamente")
    print(f"   ğŸ“Š {report['prueba_estres']['metricas_rendimiento']['total_tests']} solicitudes procesadas")
    print(f"   ğŸ¯ {report['prueba_estres']['metricas_rendimiento']['success_rate']:.1f}% de Ã©xito")
    print(f"   âš¡ {report['prueba_estres']['metricas_rendimiento']['tests_per_second']:.1f} pruebas por segundo")

if __name__ == "__main__":
    main()