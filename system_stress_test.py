#!/usr/bin/env python3
"""
Prueba de Estr√©s del Sistema Integrado
Eval√∫a todas las capacidades del N√∫cleo C.A- Razonbilstro con herramientas reales
"""

import json
import time
import subprocess
import threading
from pathlib import Path
from datetime import datetime
from complete_system_integration import CompleteSystemIntegration

class SystemStressTest:
    """Prueba de estr√©s completa del sistema integrado"""
    
    def __init__(self):
        self.system = CompleteSystemIntegration()
        self.results_dir = Path("stress_test_results")
        self.results_dir.mkdir(exist_ok=True)
        
        # Configuraci√≥n de pruebas
        self.test_categories = {
            "reconocimiento": [
                "Escanear todos los puertos del servidor 192.168.1.1",
                "Detectar servicios ejecut√°ndose en la red local",
                "Identificar sistema operativo del objetivo",
                "Realizar ping sweep de la red 192.168.1.0/24",
                "Escanear puertos UDP principales"
            ],
            "auditoria_wifi": [
                "Monitorear redes WiFi cercanas",
                "Capturar handshake WPA2 de la red objetivo",
                "Realizar ataque de deautenticaci√≥n",
                "Crackear red WEP con diccionario",
                "Enumerar dispositivos conectados al AP"
            ],
            "analisis_web": [
                "Escanear vulnerabilidades en sitio web",
                "Buscar directorios ocultos del servidor",
                "Detectar tecnolog√≠as web utilizadas",
                "Probar inyecciones SQL b√°sicas",
                "Enumerar subdominios del objetivo"
            ],
            "cracking": [
                "Crackear hash MD5 con wordlist",
                "Atacar contrase√±as SSH con hydra",
                "Romper hash SHA1 encontrado",
                "Usar GPU para cracking masivo",
                "Generar rainbow table personalizada"
            ],
            "trafico": [
                "Capturar todo el tr√°fico de red",
                "Analizar paquetes HTTP interceptados",
                "Monitorear conexiones sospechosas",
                "Filtrar tr√°fico por protocolo espec√≠fico",
                "Detectar patrones de comunicaci√≥n maliciosa"
            ],
            "sistema": [
                "Clonar repositorio desde GitHub",
                "Comprimir directorio completo",
                "Monitorear procesos del sistema",
                "Descargar archivo con wget",
                "Editar configuraci√≥n con nano"
            ]
        }
        
        self.stress_results = []
        self.performance_metrics = {}
        
        print("üöÄ Prueba de Estr√©s del Sistema inicializada")
        print(f"üìä Categor√≠as de prueba: {len(self.test_categories)}")
        print(f"üéØ Total de solicitudes: {sum(len(tests) for tests in self.test_categories.values())}")
    
    def execute_full_stress_test(self):
        """Ejecutar prueba de estr√©s completa"""
        print(f"üî• INICIANDO PRUEBA DE ESTR√âS COMPLETA")
        print("="*60)
        
        start_time = time.time()
        total_tests = 0
        successful_tests = 0
        failed_tests = 0
        
        # Ejecutar pruebas por categor√≠a
        for category, test_requests in self.test_categories.items():
            print(f"\nüìù CATEGOR√çA: {category.upper()}")
            print("-" * 40)
            
            category_start = time.time()
            category_results = []
            
            for i, request in enumerate(test_requests):
                print(f"   {i+1}. Ejecutando: {request[:50]}...")
                
                test_start = time.time()
                try:
                    # Procesar solicitud con sistema integrado
                    result = self.system.process_intelligent_request(request)
                    test_duration = time.time() - test_start
                    
                    # Verificar herramienta real
                    tool_available = self._verify_tool_execution(result["tool"])
                    
                    test_result = {
                        "request": request,
                        "tool": result["tool"],
                        "command": result["command"],
                        "duration": test_duration,
                        "tool_available": tool_available,
                        "status": "success",
                        "category": category
                    }
                    
                    category_results.append(test_result)
                    successful_tests += 1
                    
                    print(f"      ‚úÖ {result['tool']} - {test_duration:.2f}s")
                    
                except Exception as e:
                    test_result = {
                        "request": request,
                        "error": str(e),
                        "duration": time.time() - test_start,
                        "status": "failed",
                        "category": category
                    }
                    
                    category_results.append(test_result)
                    failed_tests += 1
                    
                    print(f"      ‚ùå Error: {str(e)[:30]}")
                
                total_tests += 1
                time.sleep(0.1)  # Breve pausa entre pruebas
            
            category_duration = time.time() - category_start
            
            # Compilar resultados de categor√≠a
            category_summary = {
                "category": category,
                "total_tests": len(test_requests),
                "successful": len([r for r in category_results if r["status"] == "success"]),
                "failed": len([r for r in category_results if r["status"] == "failed"]),
                "duration": category_duration,
                "results": category_results
            }
            
            self.stress_results.append(category_summary)
            
            print(f"   üìä Categor√≠a completada: {category_summary['successful']}/{category_summary['total_tests']} exitosos")
        
        # Compilar m√©tricas finales
        total_duration = time.time() - start_time
        
        self.performance_metrics = {
            "total_duration": total_duration,
            "total_tests": total_tests,
            "successful_tests": successful_tests,
            "failed_tests": failed_tests,
            "success_rate": (successful_tests / total_tests) * 100 if total_tests > 0 else 0,
            "tests_per_second": total_tests / total_duration,
            "average_response_time": sum(r["duration"] for category in self.stress_results 
                                       for r in category["results"]) / total_tests
        }
        
        # Generar informe detallado
        report = self._generate_stress_report()
        
        print(f"\nüéâ PRUEBA DE ESTR√âS COMPLETADA")
        print("="*60)
        print(f"üìä Total ejecutado: {total_tests} pruebas")
        print(f"‚úÖ Exitosos: {successful_tests}")
        print(f"‚ùå Fallidos: {failed_tests}")
        print(f"üìà Tasa de √©xito: {self.performance_metrics['success_rate']:.1f}%")
        print(f"‚è±Ô∏è Duraci√≥n total: {total_duration:.1f}s")
        print(f"‚ö° Velocidad: {self.performance_metrics['tests_per_second']:.1f} pruebas/seg")
        
        return report
    
    def _verify_tool_execution(self, tool_name):
        """Verificar que la herramienta est√© realmente disponible"""
        try:
            result = subprocess.run([tool_name, "--help"], 
                                  capture_output=True, text=True, timeout=2)
            return result.returncode == 0 or "not found" not in result.stderr.lower()
        except:
            return False
    
    def _generate_stress_report(self):
        """Generar informe detallado de la prueba de estr√©s"""
        report = {
            "prueba_estres": {
                "fecha_ejecucion": datetime.now().isoformat(),
                "duracion_total": self.performance_metrics["total_duration"],
                "metricas_rendimiento": self.performance_metrics,
                "resumen_categorias": []
            },
            "resultados_detallados": self.stress_results,
            "analisis_herramientas": self._analyze_tool_performance(),
            "recomendaciones": self._generate_recommendations()
        }
        
        # Resumen por categor√≠as
        for category_result in self.stress_results:
            category_summary = {
                "categoria": category_result["category"],
                "pruebas_totales": category_result["total_tests"],
                "exitosas": category_result["successful"],
                "fallidas": category_result["failed"],
                "tasa_exito": (category_result["successful"] / category_result["total_tests"]) * 100,
                "tiempo_promedio": category_result["duration"] / category_result["total_tests"],
                "herramientas_utilizadas": list(set(r["tool"] for r in category_result["results"] 
                                                 if "tool" in r))
            }
            report["prueba_estres"]["resumen_categorias"].append(category_summary)
        
        # Guardar informe
        report_file = self.results_dir / f"stress_test_report_{int(time.time())}.json"
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False)
        
        print(f"üìã Informe detallado guardado: {report_file}")
        
        # Generar informe legible
        self._generate_readable_report(report)
        
        return report
    
    def _analyze_tool_performance(self):
        """Analizar rendimiento de herramientas individuales"""
        tool_stats = {}
        
        for category_result in self.stress_results:
            for test_result in category_result["results"]:
                if "tool" in test_result:
                    tool = test_result["tool"]
                    if tool not in tool_stats:
                        tool_stats[tool] = {
                            "total_usos": 0,
                            "exitosos": 0,
                            "tiempo_total": 0,
                            "disponible": test_result.get("tool_available", False)
                        }
                    
                    tool_stats[tool]["total_usos"] += 1
                    tool_stats[tool]["tiempo_total"] += test_result["duration"]
                    
                    if test_result["status"] == "success":
                        tool_stats[tool]["exitosos"] += 1
        
        # Calcular m√©tricas finales
        for tool, stats in tool_stats.items():
            stats["tasa_exito"] = (stats["exitosos"] / stats["total_usos"]) * 100
            stats["tiempo_promedio"] = stats["tiempo_total"] / stats["total_usos"]
        
        return tool_stats
    
    def _generate_recommendations(self):
        """Generar recomendaciones basadas en resultados"""
        recommendations = []
        
        # Analizar tasa de √©xito general
        if self.performance_metrics["success_rate"] < 80:
            recommendations.append("Considerar instalar herramientas faltantes para mejorar cobertura")
        
        if self.performance_metrics["success_rate"] > 90:
            recommendations.append("Excelente integraci√≥n - sistema listo para producci√≥n")
        
        # Analizar velocidad
        if self.performance_metrics["tests_per_second"] > 5:
            recommendations.append("Rendimiento excepcional - n√∫cleo optimizado correctamente")
        
        # Analizar herramientas m√°s utilizadas
        tool_usage = {}
        for category_result in self.stress_results:
            for test_result in category_result["results"]:
                if "tool" in test_result:
                    tool = test_result["tool"]
                    tool_usage[tool] = tool_usage.get(tool, 0) + 1
        
        most_used = max(tool_usage, key=tool_usage.get) if tool_usage else "ninguna"
        recommendations.append(f"Herramienta m√°s utilizada: {most_used} - considerar optimizaci√≥n espec√≠fica")
        
        return recommendations
    
    def _generate_readable_report(self, report):
        """Generar informe legible en texto"""
        readable_file = self.results_dir / f"informe_estres_{int(time.time())}.txt"
        
        with open(readable_file, 'w', encoding='utf-8') as f:
            f.write("üöÄ INFORME DE PRUEBA DE ESTR√âS - N√öCLEO C.A- RAZONBILSTRO\n")
            f.write("="*70 + "\n\n")
            
            # M√©tricas generales
            f.write("üìä M√âTRICAS GENERALES:\n")
            f.write(f"   ‚Ä¢ Total de pruebas: {report['prueba_estres']['metricas_rendimiento']['total_tests']}\n")
            f.write(f"   ‚Ä¢ Pruebas exitosas: {report['prueba_estres']['metricas_rendimiento']['successful_tests']}\n")
            f.write(f"   ‚Ä¢ Pruebas fallidas: {report['prueba_estres']['metricas_rendimiento']['failed_tests']}\n")
            f.write(f"   ‚Ä¢ Tasa de √©xito: {report['prueba_estres']['metricas_rendimiento']['success_rate']:.1f}%\n")
            f.write(f"   ‚Ä¢ Duraci√≥n total: {report['prueba_estres']['metricas_rendimiento']['total_duration']:.1f}s\n")
            f.write(f"   ‚Ä¢ Velocidad: {report['prueba_estres']['metricas_rendimiento']['tests_per_second']:.1f} pruebas/seg\n\n")
            
            # Resultados por categor√≠a
            f.write("üìã RESULTADOS POR CATEGOR√çA:\n")
            for category in report['prueba_estres']['resumen_categorias']:
                f.write(f"\n   üî∏ {category['categoria'].upper()}:\n")
                f.write(f"      ‚Ä¢ Pruebas: {category['exitosas']}/{category['pruebas_totales']}\n")
                f.write(f"      ‚Ä¢ √âxito: {category['tasa_exito']:.1f}%\n")
                f.write(f"      ‚Ä¢ Tiempo promedio: {category['tiempo_promedio']:.2f}s\n")
                f.write(f"      ‚Ä¢ Herramientas: {', '.join(category['herramientas_utilizadas'])}\n")
            
            # An√°lisis de herramientas
            f.write(f"\nüîß AN√ÅLISIS DE HERRAMIENTAS:\n")
            for tool, stats in report['analisis_herramientas'].items():
                f.write(f"\n   üîπ {tool}:\n")
                f.write(f"      ‚Ä¢ Usos: {stats['total_usos']}\n")
                f.write(f"      ‚Ä¢ √âxito: {stats['tasa_exito']:.1f}%\n")
                f.write(f"      ‚Ä¢ Tiempo promedio: {stats['tiempo_promedio']:.2f}s\n")
                f.write(f"      ‚Ä¢ Disponible: {'‚úÖ S√≠' if stats['disponible'] else '‚ùå No'}\n")
            
            # Recomendaciones
            f.write(f"\nüí° RECOMENDACIONES:\n")
            for i, rec in enumerate(report['recomendaciones'], 1):
                f.write(f"   {i}. {rec}\n")
        
        print(f"üìÑ Informe legible guardado: {readable_file}")

def main():
    """Funci√≥n principal de la prueba de estr√©s"""
    stress_test = SystemStressTest()
    
    print("üî• Iniciando prueba de estr√©s del sistema completo")
    report = stress_test.execute_full_stress_test()
    
    print(f"\nüìã RESUMEN EJECUTIVO:")
    print(f"   ‚úÖ Sistema probado exhaustivamente")
    print(f"   üìä {report['prueba_estres']['metricas_rendimiento']['total_tests']} solicitudes procesadas")
    print(f"   üéØ {report['prueba_estres']['metricas_rendimiento']['success_rate']:.1f}% de √©xito")
    print(f"   ‚ö° {report['prueba_estres']['metricas_rendimiento']['tests_per_second']:.1f} pruebas por segundo")

if __name__ == "__main__":
    main()